{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy.random as r\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "names =['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "df = pd.read_csv('train.csv',header=None,sep=\",\",names=names, encoding = \"ISO-8859-1\")\n",
    "\n",
    "names_test =['id', 'comment_text']\n",
    "df_test = pd.read_csv('test.csv',header=None,sep=\",\",names=names_test, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxic_score'] = df[['toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n",
    "#drop unnecessary columns\n",
    "df = df.drop(['id', 'toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate'], axis=1)\n",
    "#drop first row\n",
    "df.drop(df.index[:1], inplace=True)\n",
    "\n",
    "df_test = df_test.drop(['id'], axis=1)\n",
    "df_test.drop(df_test.index[:1], inplace=True)\n",
    "#df.drop(df.index[:150000], inplace=True) #smaller data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "1  Yo bitch Ja Rule is more succesful then you'll...\n",
       "2  == From RfC == \\n\\n The title is fine as it is...\n",
       "3  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "4  :If you have a look back at the source, the in...\n",
       "5          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = []\n",
    "negative_file = open(\"negative-words.txt\", \"r\")\n",
    "for line in negative_file:\n",
    "    bad_words.append(line.strip(\"\\n\"))\n",
    "negative_file.close()\n",
    "profanity_file = open(\"profanity-words.txt\", \"r\")\n",
    "for line in profanity_file:\n",
    "    if (line.strip(\"\\n\") not in bad_words):\n",
    "        bad_words.append(line.strip(\"\\n\"))\n",
    "profanity_file.close()\n",
    "# print(bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "data_test = df_test.values\n",
    "\n",
    "X = data[:,0].reshape((159571,1))\n",
    "Y = data[:,1].reshape((159571,1))\n",
    "\n",
    "toxic_count = 0\n",
    "not_toxic_count = 0\n",
    "validation_count = 0\n",
    "\n",
    "X_tr = []\n",
    "Y_tr = []\n",
    "X_test = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for index in range(0,159571):\n",
    "    if (int(Y[index][0]) == 1 and toxic_count < 7500) or (int(Y[index][0]) == 0 and not_toxic_count < 7500):\n",
    "        Y_tr.append(int(Y[index][0]))\n",
    "        X_tr.append(X[index][0])\n",
    "        if (int(Y[index][0]) == 1):\n",
    "            toxic_count += 1\n",
    "        else:\n",
    "            not_toxic_count += 1\n",
    "    if toxic_count == 7500 and not_toxic_count == 7500:\n",
    "        Y_val.append(int(Y[index][0]))\n",
    "        X_val.append(X[index][0])\n",
    "        validation_count += 1\n",
    "    if validation_count == 15000:\n",
    "        break\n",
    "\n",
    "# X_tr = np.array(X_tr).reshape((15000, 1))\n",
    "Y_tr = np.array(Y_tr).reshape((15000, 1))\n",
    "Y_val = np.array(Y_val).reshape((15000, 1))\n",
    "\n",
    "for index in range(0, 15000):\n",
    "    X_test.append(data_test[index][0])\n",
    "\n",
    "cv = sklearn.feature_extraction.text.CountVectorizer(vocabulary=bad_words)\n",
    "X_tr_features = cv.fit_transform(X_tr).toarray()\n",
    "X_test_features = cv.fit_transform(X_test).toarray()\n",
    "X_val_features = cv.fit_transform(X_val).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling \n",
    "# X_tr_scale = preprocessing.scale(X_tr_features)\n",
    "X_tr_scale = X_tr_features\n",
    "# X_tr_scale = preprocessing.scale(X_tr_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.e+00 1.e-06 1.e-06 ... 1.e-06 1.e-06 1.e-06]\n",
      " [1.e+00 1.e-06 1.e-06 ... 1.e-06 1.e-06 1.e-06]\n",
      " [1.e+00 1.e-06 1.e-06 ... 1.e-06 1.e-06 1.e-06]\n",
      " ...\n",
      " [1.e+00 1.e-06 1.e-06 ... 1.e-06 1.e-06 1.e-06]\n",
      " [1.e+00 1.e-06 1.e-06 ... 1.e-06 1.e-06 1.e-06]\n",
      " [1.e+00 1.e-06 1.e-06 ... 1.e-06 1.e-06 1.e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Append a column of ones in the beginning of x_train an save in variable a.\n",
    "ones = np.ones(X_tr_scale.shape[0]).reshape((X_tr_scale.shape[0], 1))\n",
    "a = np.hstack((ones, X_tr_scale))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5214, 1)\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((a.shape[1], 1))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(a , w):\n",
    "    return sigmoid(np.dot(a, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " ...\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "yhat = hypothesis(a, w)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10397.207708399179\n"
     ]
    }
   ],
   "source": [
    "def likelihood(X_tr , Y_tr , w , n):\n",
    "    yhat = hypothesis(X_tr, w)\n",
    "    Y_tr = Y_tr.reshape((yhat.shape[0], 1))\n",
    "    likelihood = np.sum(Y_tr * ma.log(yhat) + (1 - Y_tr) * ma.log(1 - yhat))\n",
    "    return likelihood\n",
    "\n",
    "print(likelihood(a, Y_tr, w, a.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-cb412938e457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mnum_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlikelihood_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradient_Ascent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-cb412938e457>\u001b[0m in \u001b[0;36mGradient_Ascent\u001b[1;34m(a, y, learning_rate, num_iters)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Updating Parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO - Write the gradient ascent function - 25 points\n",
    "def Gradient_Ascent(a, y, learning_rate, num_iters):\n",
    "    n = a.shape[0] # Number of training examples.\n",
    "    # TODO - Initialize w. Zeros vector of shape x_train.shape[1],1\n",
    "    w = np.zeros((a.shape[1], 1))\n",
    "    # TODO - Reshape y to be a rank 2 matrix.\n",
    "    y = y.reshape((y.shape[0], 1))\n",
    "    # TODO - Initiating list to store values of likelihood after few iterations.\n",
    "    likelihood_values = []\n",
    "    for i in range(num_iters):\n",
    "        yhat = hypothesis(a, w)\n",
    "        error = y - yhat\n",
    "        gradient = np.dot(a.T, error)\n",
    "        # Updating Parameters\n",
    "        w = w + (learning_rate / n) * gradient\n",
    "        if (i % 100) == 0:\n",
    "            print(i)\n",
    "            likelihood_values.append(likelihood(a,y,w,n))\n",
    "        \n",
    "    return w, likelihood_values\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_iters = 50000\n",
    "w, likelihood_values = Gradient_Ascent(a, Y_tr, learning_rate, num_iters)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,num_iters,100))\n",
    "plt.plot(iters,likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()\n",
    "print(likelihood_values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.902667\n",
      "[[0.         0.         1.996149   ... 0.637581   0.         0.93918193]]\n",
      "[-1.37313343]\n",
      "Accuracy on validation data = 0.911600\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100000000)\n",
    "logreg.fit(X_tr_scale, Y_tr.ravel())\n",
    "# TODO - Find the predicted values on training set using logreg.predict - 5 points\n",
    "yhat = logreg.predict(X_tr_scale)\n",
    "# TODO - Find the accuracy achieved on training set using logreg.score - 5 points\n",
    "acc = logreg.score(X_tr_scale, Y_tr.ravel())\n",
    "\n",
    "print(\"Accuracy on training data = %f\" % acc)\n",
    "\n",
    "w = logreg.coef_\n",
    "intercept = logreg.intercept_\n",
    "# VERIFY - Compare the parameters computed by logreg model and gradient ascent. They should be nearly same.\n",
    "print(w)\n",
    "print(intercept)\n",
    "\n",
    "acc_val = logreg.score(X_val_features, Y_val.ravel())\n",
    "print(\"Accuracy on validation data = %f\" % acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -0.01414355 ... -0.0258285   0.\n",
      "  -0.01633211]\n",
      " [ 0.          0.         -0.01414355 ... -0.0258285   0.\n",
      "  -0.01633211]\n",
      " [ 0.          0.         -0.01414355 ... -0.0258285   0.\n",
      "  -0.01633211]\n",
      " ...\n",
      " [ 0.          0.         -0.01414355 ... -0.0258285   0.\n",
      "  -0.01633211]\n",
      " [ 0.          0.         -0.01414355 ... -0.0258285   0.\n",
      "  -0.01633211]\n",
      " [ 0.          0.         -0.01414355 ... -0.0258285   0.\n",
      "  -0.01633211]]\n",
      "[[ 0.          0.         -0.01777795 ...  0.          0.\n",
      "  -0.01777795]\n",
      " [ 0.          0.         -0.01777795 ...  0.          0.\n",
      "  -0.01777795]\n",
      " [ 0.          0.         -0.01777795 ...  0.          0.\n",
      "  -0.01777795]\n",
      " ...\n",
      " [ 0.          0.         -0.01777795 ...  0.          0.\n",
      "  -0.01777795]\n",
      " [ 0.          0.         -0.01777795 ...  0.          0.\n",
      "  -0.01777795]\n",
      " [ 0.          0.         -0.01777795 ...  0.          0.\n",
      "  -0.01777795]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "names =['id', 'comment_text']\n",
    "df = pd.read_csv('test.csv',header=None,sep=\",\",names=names, encoding = \"ISO-8859-1\")\n",
    "df = df.drop(['id'], axis=1)\n",
    "df.drop(df.index[:150000], inplace=True)\n",
    "\n",
    "X_test = df['comment_text']\n",
    "Y_test = np.zeros((df.shape[0], 1))\n",
    "    \n",
    "cv = sklearn.feature_extraction.text.CountVectorizer(vocabulary=bad_words)\n",
    "X_test_features = cv.fit_transform(X_test).toarray()\n",
    "\n",
    "X_scale = StandardScaler()\n",
    "X_tr = X_scale.fit_transform(X_tr_features)\n",
    "X_test = X_scale.fit_transform(X_test_features)\n",
    "print(X_tr)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Setting up the output layer\\ndef convert_y_to_vect(y):\\n    y_vect = np.zeros((len(y), 10))\\n    for i in range(len(y)):\\n        y_vect[i, y[i]] = 1\\n    return y_vect\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Setting up the output layer\n",
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Converting the training and test targets to vectors\\ny_v_train = convert_y_to_vect(Y_tr)\\ny_v_test = convert_y_to_vect(Y_test)\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Converting the training and test targets to vectors\n",
    "y_v_train = convert_y_to_vect(Y_tr)\n",
    "y_v_test = convert_y_to_vect(Y_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#A quick check to see that our code performs as we expect \\nprint(y_train[0:4])\\nprint(y_v_train[0:4])\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#A quick check to see that our code performs as we expect \n",
    "print(y_train[0:4])\n",
    "print(y_v_train[0:4])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def f_deriv(z):\n",
    "    return f(z) * (1 - f(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {} #creating a dictionary i.e. a set of key: value pairs\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1])) #Return “continuous uniform” random floats in the half-open interval [0.0, 1.0). \n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    a = {1: x} # create a dictionary for holding the a values for all levels\n",
    "    z = { } # create a dictionary for holding the z values for all the layers\n",
    "    for l in range(1, len(W) + 1): # for each layer\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]  # z^(l+1) = W^(l)*a^(l) + b^(l)\n",
    "        a[l+1] = f(z[l+1]) # a^(l+1) = f(z^(l+1))\n",
    "    return a, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y, a_out, z_out):\n",
    "    # delta^(nl) = -(y_i - a_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-a_out) * f_deriv(z_out) \n",
    "\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Back Propagation Algorithm\n",
    "def train_nn(nn_structure, X, y, iter_num=10, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%10 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored a and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-a[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(a^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))# np.newaxis increase the number of dimensions\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/N * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/N * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/N * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func\n",
    "\n",
    "\n",
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 100 iterations\n",
      "Iteration 0 of 100\n",
      "Iteration 10 of 100\n",
      "Iteration 20 of 100\n",
      "Iteration 30 of 100\n",
      "Iteration 40 of 100\n",
      "Iteration 50 of 100\n",
      "Iteration 60 of 100\n",
      "Iteration 70 of 100\n",
      "Iteration 80 of 100\n",
      "Iteration 90 of 100\n"
     ]
    }
   ],
   "source": [
    "num_features = len(bad_words)\n",
    "nn_structure = [num_features, 30, 1]\n",
    "    \n",
    "# train the NN\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_tr, Y_tr, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#learning curve\n",
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-628d4c6d2558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction accuracy is {}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# get the prediction accuracy and print\n",
    "X_test = X_scale.fit_transform(X_val_features)\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(Y_val, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
