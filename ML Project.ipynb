{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "df = pd.read_csv('train.csv',header=None,sep=\",\",names=names, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxic_score'] = df[['toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n",
    "#drop unnecessary columns\n",
    "df = df.drop(['id', 'toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate'], axis=1)\n",
    "#drop first row\n",
    "df.drop(df.index[:1], inplace=True)\n",
    "#df.drop(df.index[:150000], inplace=True) #smaller data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment_text toxic_score\n",
      "1       Explanation\\nWhy the edits made under my usern...           0\n",
      "2       D'aww! He matches this background colour I'm s...           0\n",
      "3       Hey man, I'm really not trying to edit war. It...           0\n",
      "4       \"\\nMore\\nI can't make any real suggestions on ...           0\n",
      "5       You, sir, are my hero. Any chance you remember...           0\n",
      "6       \"\\n\\nCongratulations from me as well, use the ...           0\n",
      "7            COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK           1\n",
      "8       Your vandalism to the Matt Shirvington article...           0\n",
      "9       Sorry if the word 'nonsense' was offensive to ...           0\n",
      "10      alignment on this subject and which are contra...           0\n",
      "11      \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...           0\n",
      "12      bbq \\n\\nbe a man and lets discuss it-maybe ove...           0\n",
      "13      Hey... what is it..\\n@ | talk .\\nWhat is it......           1\n",
      "14      Before you start throwing accusations and warn...           0\n",
      "15      Oh, and the girl above started her arguments w...           0\n",
      "16      \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...           0\n",
      "17      Bye! \\n\\nDon't look, come or think of comming ...           1\n",
      "18       REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski           0\n",
      "19      The Mitsurugi point made no sense - why not ar...           0\n",
      "20      Don't mean to bother you \\n\\nI see that you're...           0\n",
      "21      \"\\n\\n Regarding your recent edits \\n\\nOnce aga...           0\n",
      "22      \"\\nGood to know. About me, yeah, I'm studying ...           0\n",
      "23      \"\\n\\n Snowflakes are NOT always symmetrical! \\...           0\n",
      "24      \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...           0\n",
      "25      \"\\n\\nRe-considering 1st paragraph edit?\\nI don...           0\n",
      "26      Radial symmetry \\n\\nSeveral now extinct lineag...           0\n",
      "27      There's no need to apologize. A Wikipedia arti...           0\n",
      "28      Yes, because the mother of the child in the ca...           0\n",
      "29      \"\\nOk. But it will take a bit of work but I ca...           0\n",
      "30      \"== A barnstar for you! ==\\n\\n  The Real Life ...           0\n",
      "...                                                   ...         ...\n",
      "159542  Your absurd edits \\n\\nYour absurd edits on gre...           1\n",
      "159543  maybe he's got better things to do than spend ...           0\n",
      "159544  scrap that, it does meet criteria and its gone...           0\n",
      "159545                                You could do worse.           0\n",
      "159546  , 7 March 2011 (UTC)\\nAre you also User:Bmatts...           0\n",
      "159547  \"\\n\\nHey listen don't you ever!!!! Delete my e...           1\n",
      "159548                  Thank you very, very much.  Â·â           0\n",
      "159549                        Talkback: 15 September 2012           0\n",
      "159550                         2005 (UTC)\\n 06:35, 31 Mar           0\n",
      "159551  i agree/ on another note lil wayne is a talent...           0\n",
      "159552  While about half the references are from BYU-I...           0\n",
      "159553  Prague Spring \\n\\nI think that Prague Spring d...           0\n",
      "159554  I see this as having been merged; undoing one ...           0\n",
      "159555  and i'm going to keep posting the stuff u dele...           1\n",
      "159556  \"\\n\\nHow come when you download that MP3 it's ...           0\n",
      "159557  I'll be on IRC, too, if you have a more specif...           0\n",
      "159558  It is my opinion that that happens to be off-t...           0\n",
      "159559  Please stop removing content from Wikipedia; i...           0\n",
      "159560  Image:Barack-obama-mother.jpg listed for delet...           0\n",
      "159561  \"Editing of article without Consensus & Remova...           0\n",
      "159562  \"\\nNo he did not, read it again (I would have ...           0\n",
      "159563  \"\\n Auto guides and the motoring press are not...           0\n",
      "159564  \"\\nplease identify what part of BLP applies be...           0\n",
      "159565  Catalan independentism is the social movement ...           0\n",
      "159566  The numbers in parentheses are the additional ...           0\n",
      "159567  \":::::And for the second time of asking, when ...           0\n",
      "159568  You should be ashamed of yourself \\n\\nThat is ...           0\n",
      "159569  Spitzer \\n\\nUmm, theres no actual article for ...           0\n",
      "159570  And it looks like it was actually you who put ...           0\n",
      "159571  And ... I really don't think you understand.  ...           0\n",
      "\n",
      "[159571 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text toxic_score\n",
       "1  Explanation\\nWhy the edits made under my usern...           0\n",
       "2  D'aww! He matches this background colour I'm s...           0\n",
       "3  Hey man, I'm really not trying to edit war. It...           0\n",
       "4  \"\\nMore\\nI can't make any real suggestions on ...           0\n",
       "5  You, sir, are my hero. Any chance you remember...           0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = []\n",
    "negative_file = open(\"negative-words.txt\", \"r\")\n",
    "for line in negative_file:\n",
    "    bad_words.append(line.strip(\"\\n\"))\n",
    "negative_file.close()\n",
    "profanity_file = open(\"profanity-words.txt\", \"r\")\n",
    "for line in profanity_file:\n",
    "    if (line.strip(\"\\n\") not in bad_words):\n",
    "        bad_words.append(line.strip(\"\\n\"))\n",
    "profanity_file.close()\n",
    "# print(bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comment_list = df['comment_text'].to_numpy()\n",
    "# comment_list = df['comment_text'].tolist()\n",
    "# cv = sklearn.feature_extraction.text.CountVectorizer(vocabulary=bad_words)\n",
    "# print(cv.fit_transform(comment_list).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "data = df.values\n",
    "\n",
    "X = data[:,0].reshape((159571,1))\n",
    "Y = data[:,1].reshape((159571,1))\n",
    "\n",
    "toxic_count = 0\n",
    "not_toxic_count = 0\n",
    "\n",
    "X_tr = []\n",
    "Y_tr = []\n",
    "\n",
    "for index in range(0,159571):\n",
    "    if (int(Y[index][0]) == 1 and toxic_count < 7500) or (int(Y[index][0]) == 0 and not_toxic_count < 7500):\n",
    "        Y_tr.append(int(Y[index][0]))\n",
    "        X_tr.append(X[index][0])\n",
    "        if (int(Y[index][0]) == 1):\n",
    "            toxic_count += 1\n",
    "        else:\n",
    "            not_toxic_count += 1\n",
    "    if toxic_count == 7500 and not_toxic_count == 7500:\n",
    "        break\n",
    "\n",
    "# X_tr = np.array(X_tr).reshape((15000, 1))\n",
    "Y_tr = np.array(Y_tr).reshape((15000, 1))\n",
    "\n",
    "cv = sklearn.feature_extraction.text.CountVectorizer(vocabulary=bad_words)\n",
    "X_tr_features = cv.fit_transform(X_tr).toarray()\n",
    "\n",
    "print(X_tr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
